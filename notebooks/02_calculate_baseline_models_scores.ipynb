{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021-10-13:\n",
    "- Added stacking with sklearn and mlxtend\n",
    "- Moved Watermark at the end of the notebook\n",
    "\n",
    "2021-10-11:\n",
    "- Initial version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open tasks\n",
    "- TODO: Add LogisticRegression classifier\n",
    "- TODO: Add better function to submit best baseline results (stacked or non-stacked)\n",
    "- TODO: Write function to write scores into a dataframe/csv-file for better documentation and tracking\n",
    "- TODO: Refactor write_scores_to_json() or replace it with df/csv-file approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of **stage two** of my machine learning process is to calculate the **baseline score of un-optimized ML algorithms** as a baseline for future optimization, including feature selection/reduction, feature normalization/transformation, and hyper-parameters tuning. The workflow will use the optimized dataframes (reduced storage and memory usage). For this competition, we are focusing on the **ROC AUC score**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Basic Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest of the modules are loaded when required.\n",
    "# To ensure a standalone character (for easier reusability).\n",
    "import joblib\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs used: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import configparser\n",
    "\n",
    "# Load external config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../resources/config.ini\")\n",
    "\n",
    "PATH_DATA_RAW = config[\"PATHS\"][\"PATH_DATA_RAW\"]\n",
    "PATH_DATA_INT = config[\"PATHS\"][\"PATH_DATA_INT\"]\n",
    "PATH_DATA_PRO = config[\"PATHS\"][\"PATH_DATA_PRO\"]\n",
    "PATH_REPORTS = config[\"PATHS\"][\"PATH_REPORTS\"]\n",
    "PATH_MODELS = config[\"PATHS\"][\"PATH_MODELS\"]\n",
    "PATH_SUB = config[\"PATHS\"][\"PATH_SUB\"]\n",
    "\n",
    "# Telegram Bot\n",
    "token = config[\"TELEGRAM\"][\"token\"]\n",
    "chat_id = config[\"TELEGRAM\"][\"chat_id\"]\n",
    "FILENAME_NB = \"02_baseline_models\" # for Telegram messages\n",
    "\n",
    "# Set global randome state\n",
    "rnd_state = 42\n",
    "\n",
    "# Define available cpu cores\n",
    "n_cpu = os.cpu_count()\n",
    "print(\"Number of CPUs used:\", n_cpu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, requests #for Telegram notifications\n",
    "\n",
    "def send_telegram_message(message):\n",
    "    \"\"\"Sending messages to Telegram bot via requests.get().\"\"\"\n",
    "    \n",
    "    message = f\"{FILENAME_NB}:\\n{message}\"\n",
    "\n",
    "    # Using \"try and except\" to ensure that the notebook execution will not be stopped only because of problems with the bot.\n",
    "    # Example: No network connection.\n",
    "    # ISSUE: Be careful, an error messages will leak your Telegram Bot Token when uploaded to GitHub.\n",
    "    try:\n",
    "        url = 'https://api.telegram.org/bot%s/sendMessage?chat_id=%s&text=%s'%(token, chat_id, urllib.parse.quote_plus(message))\n",
    "        _ = requests.get(url, timeout=10)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('\\n\\nSending message to Telegram Bot was not successful.\\n\\n')\n",
    "        print(e)\n",
    "        \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_train_scores(model, X_train, y_train, y_train_pred):\n",
    "    # Training set performance\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)  # Calculate Accuracy\n",
    "    train_mcc = matthews_corrcoef(y_train, y_train_pred)  # Calculate MCC\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")  # Calculate F1-score\n",
    "    train_rocauc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "    \n",
    "    return train_accuracy, train_mcc, train_f1, train_rocauc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_valid_scores(model, X_valid, y_valid, y_valid_pred):\n",
    "    # Validation set performance\n",
    "    valid_accuracy = accuracy_score(y_valid, y_valid_pred)  # Calculate Accuracy\n",
    "    valid_mcc = matthews_corrcoef(y_valid, y_valid_pred)  # Calculate MCC\n",
    "    valid_f1 = f1_score(y_valid, y_valid_pred, average=\"weighted\")  # Calculate F1-score\n",
    "    valid_rocauc = roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1])\n",
    "\n",
    "    return valid_accuracy, valid_mcc, valid_f1, valid_rocauc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores():\n",
    "    print(\"Model performance for Training set\")\n",
    "    print(\"- Accuracy: %s\" % train_accuracy)\n",
    "    print(\"- MCC: %s\" % train_mcc)\n",
    "    print(\"- F1 score: %s\" % train_f1)\n",
    "    print(\"- ROC AUC score: %s\" % train_rocauc)\n",
    "    print(\"----------------------------------\")\n",
    "    print(\"Model performance for Validation set\")\n",
    "    print(\"- Accuracy: %s\" % valid_accuracy)\n",
    "    print(\"- MCC: %s\" % valid_mcc)\n",
    "    print(\"- F1 score: %s\" % valid_f1)\n",
    "    print(\"- ROC AUC score: %s\" % valid_rocauc)\n",
    "\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def write_scores_to_json(filename):\n",
    "    dummy_scores_dict = {}\n",
    "    dummy_scores_list = []\n",
    "\n",
    "    dummy_scores_dict['Accuracy Train'] = train_accuracy\n",
    "    dummy_scores_dict['MCC Train'] = train_mcc\n",
    "    dummy_scores_dict['F1 Train'] = train_f1\n",
    "    dummy_scores_dict['ROC AUC Train'] = train_rocauc\n",
    "    dummy_scores_list.append(dummy_scores_dict)\n",
    "\n",
    "    dummy_scores_dict = {}\n",
    "    dummy_scores_dict['Accuracy Valid'] = valid_accuracy\n",
    "    dummy_scores_dict['MCC Valid'] = valid_mcc\n",
    "    dummy_scores_dict['F1 Valid'] = valid_f1\n",
    "    dummy_scores_dict['ROC AUC Valid'] = valid_rocauc\n",
    "    dummy_scores_list.append(dummy_scores_dict)\n",
    "\n",
    "    # datetime object containing current date and time\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Serializing and write json file\n",
    "    json_object = json.dumps(dummy_scores_list, indent = 4) \n",
    "    filename =  now+'_'+filename\n",
    "    with open(PATH_REPORTS + filename, \"w\") as outfile: \n",
    "        outfile.write(json_object)\n",
    "\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_pickle(PATH_DATA_INT + \"train.pkl\")\n",
    "# train_df = pd.read_pickle(PATH_DATA_INT + \"train_features.pkl\")\n",
    "train_df = pd.read_pickle(PATH_DATA_INT + \"train-opt.pkl\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 287)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing sample size\n",
    "# sample_size = 500000\n",
    "# X = train_df[:sample_size]\n",
    "# y = train_df[:sample_size]['target']\n",
    "# assert y.index.tolist() == X.index.tolist()\n",
    "# X = X.drop(['id','target'], axis=1)\n",
    "\n",
    "# Using full dataset\n",
    "#X = train_df.drop([\"id\", \"target\"], axis=1).to_numpy()\n",
    "#y = train_df[\"target\"].to_numpy()\n",
    "\n",
    "\n",
    "# Using numpy arrays: https://vitalflux.com/pandas-dataframe-vs-numpy-array-what-to-use/\n",
    "X = train_df.drop([\"id\", \"target\"], axis=1).values # using numpy array\n",
    "y = train_df[\"target\"].values # using numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 285), (1000000,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Baseline Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable / disable baseline classifiers\n",
    "# Do not forget to add/remove classifiers in the stacking section, accordingly\n",
    "dummy_enabled = \"yes\"\n",
    "xgbc_enabled = \"yes\"\n",
    "lgbc_enabled = \"yes\"\n",
    "ctbc_enabled = \"yes\"\n",
    "rfc_enabled = \"yes\" # Carefurl: tree grows big: .pkl file is around 1GB\n",
    "dtc_enabled = \"yes\"\n",
    "knnc_enabled = \"no\" # disable when sample size > 100.000\n",
    "mlpc_enabled = \"yes\"\n",
    "\n",
    "# Evaluation Metric\n",
    "eval_metric = \"AUC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=rnd_state, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((670000, 285), (330000, 285))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending for first bot message\n",
    "message = \"------------START------------\"\n",
    "send_telegram_message(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.4998268656716418\n",
      "- MCC: -0.0003463354277785677\n",
      "- F1 score: 0.49982698277168613\n",
      "- ROC AUC score: 0.49949268018636084\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.5001787878787879\n",
      "- MCC: 0.00035527903417098533\n",
      "- F1 score: 0.5001782036921849\n",
      "- ROC AUC score: 0.5014336197135231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Define model\n",
    "duc = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "if dummy_enabled == \"yes\":\n",
    "    try:\n",
    "        # Train model\n",
    "        duc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = duc.predict(X_train)\n",
    "        y_valid_pred = duc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(\n",
    "            duc, X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(\n",
    "            duc, X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        print_scores()\n",
    "        filename = \"dummy_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        message = f\"DummyClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {duc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f\"\\n{e}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.7885149253731343\n",
      "- MCC: 0.5783763916849866\n",
      "- F1 score: 0.7882806509204838\n",
      "- ROC AUC score: 0.8778781226320046\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.7651151515151515\n",
      "- MCC: 0.5315687193750236\n",
      "- F1 score: 0.7648343751609188\n",
      "- ROC AUC score: 0.8506886352480831\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "if xgbc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        xgbc = xgb.XGBClassifier(\n",
    "            random_state=rnd_state,\n",
    "            n_jobs=n_cpu,\n",
    "            eval_metric=eval_metric.lower()\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        xgbc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = xgbc.predict(X_train)\n",
    "        y_valid_pred = xgbc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(\n",
    "            xgbc, X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(\n",
    "            xgbc, X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"xgbc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"xgbc_baseline_model.pkl\"\n",
    "        joblib.dump(xgbc, PATH_MODELS + filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"XGBClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {xgbc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f\"\\n{e}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.7692074626865671\n",
      "- MCC: 0.5407198263980905\n",
      "- F1 score: 0.7687344285456974\n",
      "- ROC AUC score: 0.854384504730348\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.7650333333333333\n",
      "- MCC: 0.5323016233554332\n",
      "- F1 score: 0.7645593989397934\n",
      "- ROC AUC score: 0.8488486880634127\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "if lgbc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        lgbc = lgb.LGBMClassifier(\n",
    "            random_state=rnd_state,\n",
    "            n_jobs=n_cpu,\n",
    "            eval_metric=eval_metric\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        lgbc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = lgbc.predict(X_train)\n",
    "        y_valid_pred = lgbc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(lgbc,\n",
    "            X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(lgbc,\n",
    "            X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"lgbc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"lgbc_baseline_model.pkl\"\n",
    "        joblib.dump(lgbc, PATH_MODELS+filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"LGBClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {lgbc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9036059701492537\n",
      "- MCC: 0.8073152161203432\n",
      "- F1 score: 0.903600707651649\n",
      "- ROC AUC score: 0.8583491905558767\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.7678545454545455\n",
      "- MCC: 0.5373560296446442\n",
      "- F1 score: 0.7675149302948873\n",
      "- ROC AUC score: 0.8528049101122387\n"
     ]
    }
   ],
   "source": [
    "import catboost as ctb\n",
    "\n",
    "def run_catboost_calssifier():\n",
    "    if ctbc_enabled == \"yes\":\n",
    "        try:\n",
    "            # Define model\n",
    "            ctbc = ctb.CatBoostClassifier(\n",
    "                random_state=rnd_state,\n",
    "                verbose=0,\n",
    "                eval_metric=eval_metric,\n",
    "                task_type=\"GPU\"\n",
    "            )\n",
    "\n",
    "            # Train model\n",
    "            ctbc.fit(X_train, y_train)\n",
    "\n",
    "            # Make predictions\n",
    "            y_train_pred = ctbc.predict(X_train)\n",
    "            y_valid_pred = ctbc.predict(X_valid)\n",
    "\n",
    "            # Training set performance\n",
    "            train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(ctbc,\n",
    "                X_train, y_train, y_train_pred\n",
    "            )\n",
    "\n",
    "            # Validation set performance\n",
    "            valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(ctbc,\n",
    "                X_valid, y_valid, y_valid_pred\n",
    "            )\n",
    "\n",
    "            # Print and write scores\n",
    "            print_scores()\n",
    "            filename = \"ctbc_baseline_scores.json\"\n",
    "            write_scores_to_json(filename)\n",
    "\n",
    "            # Store base model\n",
    "            filename = \"ctbc_baseline_model.pkl\"\n",
    "            joblib.dump(ctbc, PATH_MODELS+filename)\n",
    "\n",
    "            # Send messages\n",
    "            message = (f\"CatBoostClassifier finished. Validation AUC ROC Score: {valid_rocauc}\")\n",
    "            send_telegram_message(message)\n",
    "\n",
    "        except Exception as e:\n",
    "            message = f\"\\nFitting of {ctbc} failed: {e}\\n\"\n",
    "            send_telegram_message(message)\n",
    "            print(f'\\n{e}\\n')\n",
    "\n",
    "    return None\n",
    "    \n",
    "run_catboost_calssifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 1.0\n",
      "- MCC: 1.0\n",
      "- F1 score: 1.0\n",
      "- ROC AUC score: 1.0\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.7576484848484848\n",
      "- MCC: 0.5178946298618594\n",
      "- F1 score: 0.7570631117247801\n",
      "- ROC AUC score: 0.8309505821426962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "if rfc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        rfc = RandomForestClassifier(random_state=rnd_state, n_jobs=n_cpu)\n",
    "\n",
    "        # Train model\n",
    "        rfc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = rfc.predict(X_train)\n",
    "        y_valid_pred = rfc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(rfc,\n",
    "            X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(rfc,\n",
    "            X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"rfc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"rfc_baseline_model.pkl\"\n",
    "        joblib.dump(rfc, PATH_MODELS+filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"RandomForestClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {rfc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.7572373134328358\n",
      "- MCC: 0.5195936906271718\n",
      "- F1 score: 0.7560729947797653\n",
      "- ROC AUC score: 0.8203079886926381\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.7559848484848485\n",
      "- MCC: 0.5169942047093701\n",
      "- F1 score: 0.7548307158115667\n",
      "- ROC AUC score: 0.8191484611827587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "if dtc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        dtc = DecisionTreeClassifier(max_depth=5, random_state=rnd_state)\n",
    "\n",
    "        # Train model\n",
    "        dtc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = dtc.predict(X_train)\n",
    "        y_valid_pred = dtc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(dtc,\n",
    "            X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(dtc,\n",
    "            X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"dtc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"dtc_baseline_model.pkl\"\n",
    "        joblib.dump(dtc, PATH_MODELS+filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"DecisionTreeClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {dtc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "if knnc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        knnc = KNeighborsClassifier(n_neighbors=3, n_jobs=n_cpu)\n",
    "\n",
    "        # Train model\n",
    "        knnc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = knnc.predict(X_train)\n",
    "        y_valid_pred = knnc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(knnc,\n",
    "            X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(knnc,\n",
    "            X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"knnc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"knnc_baseline_model.pkl\"\n",
    "        joblib.dump(knnc, PATH_MODELS+filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"KNNClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {knnc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.7634343283582089\n",
      "- MCC: 0.5281439309986606\n",
      "- F1 score: 0.7631635345656835\n",
      "- ROC AUC score: 0.8453865350764336\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.7625575757575758\n",
      "- MCC: 0.5264326747700689\n",
      "- F1 score: 0.762275633123674\n",
      "- ROC AUC score: 0.8438438724482327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "if mlpc_enabled == \"yes\":\n",
    "    try:\n",
    "        # Define model\n",
    "        mlpc = MLPClassifier(alpha=1, max_iter=200, random_state=rnd_state)\n",
    "\n",
    "        # Train model\n",
    "        mlpc.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = mlpc.predict(X_train)\n",
    "        y_valid_pred = mlpc.predict(X_valid)\n",
    "\n",
    "        # Training set performance\n",
    "        train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(mlpc,\n",
    "            X_train, y_train, y_train_pred\n",
    "        )\n",
    "\n",
    "        # Validation set performance\n",
    "        valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(mlpc,\n",
    "            X_valid, y_valid, y_valid_pred\n",
    "        )\n",
    "\n",
    "        # Print and write scores\n",
    "        print_scores()\n",
    "        filename = \"mlpc_baseline_scores.json\"\n",
    "        write_scores_to_json(filename)\n",
    "\n",
    "        # Store base model\n",
    "        filename = \"mlpc_baseline_model.pkl\"\n",
    "        joblib.dump(mlpc, PATH_MODELS+filename)\n",
    "\n",
    "        # Send messages\n",
    "        message = f\"MLPClassifier finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "        send_telegram_message(message)\n",
    "\n",
    "    except Exception as e:\n",
    "        message = f\"\\nFitting of {mlpc} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackingClassifier (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/stacking-made-easy-with-sklearn-e27a0793c92b\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9036059701492537\n",
      "- MCC: 0.8073152161203432\n",
      "- F1 score: 0.903600707651649\n",
      "- ROC AUC score: 0.9798443734467536\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.7640212121212121\n",
      "- MCC: 0.5294831336086517\n",
      "- F1 score: 0.7637158266869781\n",
      "- ROC AUC score: 0.8463956069688718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier # only works with estimators from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators = [\n",
    "    (\"rfc\", rfc),\n",
    "    (\"dtc\", dtc),\n",
    "    # (\"knnc\", knnc),\n",
    "    (\"mlpc\", mlpc),\n",
    "]\n",
    "\n",
    "final_estimator = LogisticRegression(random_state=rnd_state)\n",
    "\n",
    "# Build stack model\n",
    "stack_skl_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator) \n",
    "\n",
    "try:\n",
    "    # Train stacked model\n",
    "    stack_skl_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = stack_skl_model.predict(X_train)\n",
    "    y_valid_pred = stack_skl_model.predict(X_valid)\n",
    "\n",
    "    # Training set performance\n",
    "    train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(\n",
    "        stack_skl_model, X_train, y_train, y_train_pred\n",
    "    )\n",
    "\n",
    "    # Validation set performance\n",
    "    valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(\n",
    "        stack_skl_model, X_valid, y_valid, y_valid_pred\n",
    "    )\n",
    "\n",
    "    # Print and write scores\n",
    "    print_scores()\n",
    "    filename = \"stack_sklearn_baseline_scores.json\"\n",
    "    write_scores_to_json(filename)\n",
    "\n",
    "    # Store base model\n",
    "    filename = \"stack_sklearn_baseline_model.pkl\"\n",
    "    joblib.dump(stack_skl_model, PATH_MODELS+filename)\n",
    "\n",
    "    # Send messages\n",
    "    message = f\"Stacking (sklearn) finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "    send_telegram_message(message)\n",
    "\n",
    "except Exception as e:\n",
    "        message = f\"\\nFitting of {stack_skl_model} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackingCVClassifier (mlxtend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://developer.ibm.com/articles/stack-machine-learning-models-get-better-results/\n",
    "- http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 classifiers...\n",
      "Fitting classifier1: xgbclassifier (1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   5 | elapsed: 21.3min remaining: 32.0min\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   5 | elapsed: 21.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: lgbmclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   5 | elapsed:  1.8min remaining:  2.7min\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   5 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: catboostclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   5 | elapsed:  3.3min remaining:  5.0min\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   5 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9036059701492537\n",
      "- MCC: 0.8073152161203432\n",
      "- F1 score: 0.903600707651649\n",
      "- ROC AUC score: 0.8583491905558767\n",
      "----------------------------------\n",
      "Model performance for Validation set\n",
      "- Accuracy: 0.7678545454545455\n",
      "- MCC: 0.5373560296446442\n",
      "- F1 score: 0.7675149302948873\n",
      "- ROC AUC score: 0.8528049101122387\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "lr = LogisticRegression(random_state=rnd_state)\n",
    "\n",
    "stack_mlx_model = StackingCVClassifier(\n",
    "    classifiers=[xgbc, lgbc, ctbc],\n",
    "    meta_classifier=lr\n",
    "    cv=5,\n",
    "    use_features_in_secondary=True,\n",
    "    store_train_meta_features=True,\n",
    "    shuffle=True,\n",
    "    random_state=rnd_state,\n",
    "    verbose=1,\n",
    "    n_jobs=n_cpu\n",
    ")\n",
    "\n",
    "try:\n",
    "    stack_mlx_model.fit(X_train, y_train)\n",
    "    y_valid_pred = stack_mlx_model.predict(X_valid)\n",
    "\n",
    "    # Training set performance\n",
    "    train_accuracy, train_mcc, train_f1, train_rocauc = calculate_train_scores(\n",
    "        stack_mlx_model, X_train, y_train, y_train_pred\n",
    "    )\n",
    "\n",
    "    # Validation set performance\n",
    "    valid_accuracy, valid_mcc, valid_f1, valid_rocauc = calculate_valid_scores(\n",
    "        stack_mlx_model, X_valid, y_valid, y_valid_pred\n",
    "    )\n",
    "\n",
    "    # Print and write scores\n",
    "    print_scores()\n",
    "    filename = \"stack_sklearn_baseline_scores.json\"\n",
    "    write_scores_to_json(filename)\n",
    "\n",
    "    # Store base model\n",
    "    filename = \"stack_mlxtend_baseline_model.pkl\"\n",
    "    joblib.dump(stack_mlx_model, PATH_MODELS+filename)\n",
    "\n",
    "    # Send messages\n",
    "    message = f\"Stacking (mlxtend) finished. Validation AUC ROC Score: {valid_rocauc}\"\n",
    "    send_telegram_message(message)\n",
    "\n",
    "except Exception as e:\n",
    "        message = f\"\\nFitting of {stack_mlx_model} failed: {e}\\n\"\n",
    "        send_telegram_message(message)\n",
    "        print(f'\\n{e}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make final predications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 285)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_pickle(PATH_DATA_INT + \"test-opt.pkl\")\n",
    "X_test = test_df.drop(\"id\", axis=1).values\n",
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (best) model on \"full\" data set\n",
    "# _ = stack_skl_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_test_pred = stack_skl_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit (Best) Baseline Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section needs to be finalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-14_submission_stacked-sklearn-baseline.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "objective = \"stack_mlx_model-baseline\"\n",
    "\n",
    "curr_submission_fn = f\"{now}_submission_{objective}.csv\"\n",
    "\n",
    "my_submission = pd.DataFrame({\"id\": test_df[\"id\"], \"target\": y_test_pred})\n",
    "my_submission.to_csv(PATH_SUB + curr_submission_fn, index=False)\n",
    "\n",
    "print(curr_submission_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Tabular Playground Series - Oct 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/5.25M [00:00<?, ?B/s]\n",
      "  0%|          | 8.00k/5.25M [00:00<01:38, 55.9kB/s]\n",
      "  2%|▏         | 112k/5.25M [00:00<00:10, 536kB/s]  \n",
      "  4%|▍         | 208k/5.25M [00:00<00:07, 693kB/s]\n",
      "  5%|▌         | 288k/5.25M [00:00<00:10, 506kB/s]\n",
      "  7%|▋         | 352k/5.25M [00:00<00:11, 455kB/s]\n",
      "  8%|▊         | 408k/5.25M [00:00<00:12, 419kB/s]\n",
      "  8%|▊         | 456k/5.25M [00:01<00:12, 408kB/s]\n",
      "  9%|▉         | 504k/5.25M [00:01<00:12, 400kB/s]\n",
      " 10%|█         | 552k/5.25M [00:01<00:12, 393kB/s]\n",
      " 11%|█         | 592k/5.25M [00:01<00:12, 379kB/s]\n",
      " 12%|█▏        | 632k/5.25M [00:01<00:12, 385kB/s]\n",
      " 13%|█▎        | 672k/5.25M [00:01<00:12, 378kB/s]\n",
      " 13%|█▎        | 712k/5.25M [00:01<00:12, 371kB/s]\n",
      " 14%|█▍        | 752k/5.25M [00:01<00:12, 381kB/s]\n",
      " 15%|█▍        | 792k/5.25M [00:01<00:12, 373kB/s]\n",
      " 15%|█▌        | 832k/5.25M [00:02<00:12, 373kB/s]\n",
      " 16%|█▌        | 872k/5.25M [00:02<00:12, 369kB/s]\n",
      " 19%|█▉        | 1.02M/5.25M [00:02<00:06, 731kB/s]\n",
      " 21%|██        | 1.09M/5.25M [00:02<00:07, 559kB/s]\n",
      " 22%|██▏       | 1.16M/5.25M [00:02<00:08, 497kB/s]\n",
      " 23%|██▎       | 1.21M/5.25M [00:02<00:09, 453kB/s]\n",
      " 24%|██▍       | 1.27M/5.25M [00:03<00:09, 424kB/s]\n",
      " 25%|██▌       | 1.31M/5.25M [00:03<00:09, 413kB/s]\n",
      " 26%|██▌       | 1.36M/5.25M [00:03<00:10, 399kB/s]\n",
      " 27%|██▋       | 1.41M/5.25M [00:03<00:10, 393kB/s]\n",
      " 28%|██▊       | 1.45M/5.25M [00:03<00:10, 386kB/s]\n",
      " 28%|██▊       | 1.48M/5.25M [00:04<00:24, 158kB/s]\n",
      " 33%|███▎      | 1.71M/5.25M [00:04<00:08, 429kB/s]\n",
      " 34%|███▍      | 1.80M/5.25M [00:04<00:08, 410kB/s]\n",
      " 36%|███▌      | 1.87M/5.25M [00:04<00:08, 394kB/s]\n",
      " 37%|███▋      | 1.93M/5.25M [00:04<00:08, 391kB/s]\n",
      " 38%|███▊      | 1.98M/5.25M [00:05<00:08, 389kB/s]\n",
      " 39%|███▉      | 2.04M/5.25M [00:05<00:08, 383kB/s]\n",
      " 40%|███▉      | 2.09M/5.25M [00:05<00:08, 382kB/s]\n",
      " 41%|████      | 2.13M/5.25M [00:05<00:08, 379kB/s]\n",
      " 42%|████▏     | 2.18M/5.25M [00:05<00:08, 378kB/s]\n",
      " 42%|████▏     | 2.22M/5.25M [00:05<00:08, 373kB/s]\n",
      " 43%|████▎     | 2.26M/5.25M [00:05<00:08, 373kB/s]\n",
      " 44%|████▍     | 2.30M/5.25M [00:06<00:08, 373kB/s]\n",
      " 45%|████▍     | 2.34M/5.25M [00:06<00:08, 368kB/s]\n",
      " 45%|████▌     | 2.38M/5.25M [00:06<00:07, 378kB/s]\n",
      " 46%|████▌     | 2.41M/5.25M [00:06<00:08, 366kB/s]\n",
      " 47%|████▋     | 2.45M/5.25M [00:06<00:07, 372kB/s]\n",
      " 48%|████▊     | 2.49M/5.25M [00:06<00:07, 371kB/s]\n",
      " 48%|████▊     | 2.53M/5.25M [00:06<00:07, 369kB/s]\n",
      " 49%|████▉     | 2.57M/5.25M [00:06<00:07, 366kB/s]\n",
      " 50%|████▉     | 2.61M/5.25M [00:06<00:07, 365kB/s]\n",
      " 50%|█████     | 2.65M/5.25M [00:07<00:07, 372kB/s]\n",
      " 51%|█████     | 2.69M/5.25M [00:07<00:07, 375kB/s]\n",
      " 52%|█████▏    | 2.73M/5.25M [00:07<00:07, 369kB/s]\n",
      " 53%|█████▎    | 2.77M/5.25M [00:07<00:07, 365kB/s]\n",
      " 53%|█████▎    | 2.80M/5.25M [00:07<00:06, 367kB/s]\n",
      " 54%|█████▍    | 2.84M/5.25M [00:07<00:06, 375kB/s]\n",
      " 55%|█████▍    | 2.88M/5.25M [00:07<00:06, 369kB/s]\n",
      " 56%|█████▌    | 2.92M/5.25M [00:07<00:06, 371kB/s]\n",
      " 56%|█████▋    | 2.96M/5.25M [00:07<00:06, 364kB/s]\n",
      " 57%|█████▋    | 3.00M/5.25M [00:08<00:06, 357kB/s]\n",
      " 58%|█████▊    | 3.04M/5.25M [00:08<00:06, 352kB/s]\n",
      " 59%|█████▊    | 3.08M/5.25M [00:08<00:06, 362kB/s]\n",
      " 59%|█████▉    | 3.12M/5.25M [00:08<00:11, 187kB/s]\n",
      " 62%|██████▏   | 3.27M/5.25M [00:08<00:04, 417kB/s]\n",
      " 64%|██████▎   | 3.34M/5.25M [00:09<00:05, 398kB/s]\n",
      " 65%|██████▍   | 3.39M/5.25M [00:09<00:05, 388kB/s]\n",
      " 66%|██████▌   | 3.45M/5.25M [00:09<00:04, 386kB/s]\n",
      " 67%|██████▋   | 3.49M/5.25M [00:09<00:04, 383kB/s]\n",
      " 67%|██████▋   | 3.54M/5.25M [00:09<00:04, 386kB/s]\n",
      " 68%|██████▊   | 3.59M/5.25M [00:09<00:04, 377kB/s]\n",
      " 69%|██████▉   | 3.62M/5.25M [00:09<00:04, 371kB/s]\n",
      " 70%|██████▉   | 3.66M/5.25M [00:09<00:04, 375kB/s]\n",
      " 71%|███████   | 3.70M/5.25M [00:10<00:04, 372kB/s]\n",
      " 71%|███████▏  | 3.74M/5.25M [00:10<00:04, 370kB/s]\n",
      " 72%|███████▏  | 3.78M/5.25M [00:10<00:04, 376kB/s]\n",
      " 73%|███████▎  | 3.82M/5.25M [00:10<00:04, 373kB/s]\n",
      " 74%|███████▎  | 3.86M/5.25M [00:10<00:03, 377kB/s]\n",
      " 74%|███████▍  | 3.90M/5.25M [00:10<00:03, 372kB/s]\n",
      " 75%|███████▌  | 3.94M/5.25M [00:10<00:03, 377kB/s]\n",
      " 76%|███████▌  | 3.98M/5.25M [00:10<00:03, 366kB/s]\n",
      " 77%|███████▋  | 4.02M/5.25M [00:10<00:03, 365kB/s]\n",
      " 77%|███████▋  | 4.05M/5.25M [00:11<00:03, 371kB/s]\n",
      " 78%|███████▊  | 4.09M/5.25M [00:11<00:03, 377kB/s]\n",
      " 79%|███████▉  | 4.13M/5.25M [00:11<00:03, 369kB/s]\n",
      " 80%|███████▉  | 4.17M/5.25M [00:11<00:02, 376kB/s]\n",
      " 80%|████████  | 4.21M/5.25M [00:11<00:02, 375kB/s]\n",
      " 81%|████████  | 4.25M/5.25M [00:11<00:02, 360kB/s]\n",
      " 82%|████████▏ | 4.30M/5.25M [00:11<00:02, 379kB/s]\n",
      " 83%|████████▎ | 4.34M/5.25M [00:11<00:02, 373kB/s]\n",
      " 83%|████████▎ | 4.38M/5.25M [00:11<00:02, 369kB/s]\n",
      " 84%|████████▍ | 4.41M/5.25M [00:12<00:02, 380kB/s]\n",
      " 85%|████████▍ | 4.45M/5.25M [00:12<00:02, 368kB/s]\n",
      " 86%|████████▌ | 4.49M/5.25M [00:12<00:02, 368kB/s]\n",
      " 86%|████████▋ | 4.53M/5.25M [00:12<00:01, 374kB/s]\n",
      " 87%|████████▋ | 4.57M/5.25M [00:12<00:01, 373kB/s]\n",
      " 88%|████████▊ | 4.61M/5.25M [00:12<00:01, 377kB/s]\n",
      " 89%|████████▊ | 4.65M/5.25M [00:12<00:01, 370kB/s]\n",
      " 89%|████████▉ | 4.69M/5.25M [00:12<00:01, 366kB/s]\n",
      " 90%|█████████ | 4.73M/5.25M [00:12<00:01, 368kB/s]\n",
      " 91%|█████████ | 4.77M/5.25M [00:13<00:01, 375kB/s]\n",
      " 92%|█████████▏| 4.80M/5.25M [00:13<00:01, 367kB/s]\n",
      " 92%|█████████▏| 4.84M/5.25M [00:13<00:01, 338kB/s]\n",
      " 93%|█████████▎| 4.88M/5.25M [00:13<00:01, 196kB/s]\n",
      " 94%|█████████▍| 4.94M/5.25M [00:13<00:01, 258kB/s]\n",
      " 97%|█████████▋| 5.07M/5.25M [00:13<00:00, 457kB/s]\n",
      " 98%|█████████▊| 5.13M/5.25M [00:14<00:00, 411kB/s]\n",
      " 99%|█████████▉| 5.19M/5.25M [00:14<00:00, 404kB/s]\n",
      "100%|█████████▉| 5.23M/5.25M [00:14<00:00, 397kB/s]\n",
      "100%|██████████| 5.25M/5.25M [00:16<00:00, 340kB/s]\n"
     ]
    }
   ],
   "source": [
    "# !kaggle competitions submit tabular-playground-series-oct-2021 -f {PATH_SUB+curr_submission_fn} -m {curr_submission_fn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2021-10-14T20:08:15.118277+02:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.28.0\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 158 Stepping 13, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm: 2.3.1\n",
      "pandas  : 1.0.5\n",
      "requests: 2.26.0\n",
      "sys     : 3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]\n",
      "joblib  : 1.0.0\n",
      "catboost: 1.0.0\n",
      "xgboost : 1.1.1\n",
      "json    : 2.0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10ed364d45814f4af10e5aa088ae4ff654add15d6190d9b5a11312a81b7ebe3d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
